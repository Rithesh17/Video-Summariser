WEBVTT - https://subtitletools.com

00:00:01.070 --> 00:00:03.720
>> Deep learning with neural networks has

00:00:03.720 --> 00:00:05.850
opened up a whole new world of possibilities for

00:00:05.850 --> 00:00:10.230
building AI solutions including huge advances in computer vision.

00:00:10.230 --> 00:00:12.840
Now of course you know that an image is just an array of

00:00:12.840 --> 00:00:15.990
numbers representing pixel intensities.

00:00:15.990 --> 00:00:18.630
So in theory, we could just feed

00:00:18.630 --> 00:00:21.855
the pixel values into a fully connected neural network,

00:00:21.855 --> 00:00:24.090
and get a class prediction.

00:00:24.090 --> 00:00:27.260
In practice, we don't actually feed

00:00:27.260 --> 00:00:30.455
the image data directly into a fully connected network like this.

00:00:30.455 --> 00:00:33.050
Because it would include a whole bunch of pixel values that

00:00:33.050 --> 00:00:36.350
don't have anything to do with the class of object in the image.

00:00:36.350 --> 00:00:39.500
We need a smart approach that extracts

00:00:39.500 --> 00:00:41.045
meaningful features from the image

00:00:41.045 --> 00:00:43.460
before trying to predict its class.

00:00:43.460 --> 00:00:47.525
What we do is we apply multiple filter kernels,

00:00:47.525 --> 00:00:51.020
each initialized with some random weights to the image.

00:00:51.020 --> 00:00:53.810
We convolve the filter kernels across

00:00:53.810 --> 00:00:56.720
the image so that each one produces a feature map.

00:00:56.720 --> 00:00:59.510
Typically, we apply a rectified linear unit or

00:00:59.510 --> 00:01:01.520
ReLU activation function to

00:01:01.520 --> 00:01:04.670
convert any negative pixel values to zero.

00:01:04.670 --> 00:01:08.260
After one or more convolution layers,

00:01:08.260 --> 00:01:11.785
we can also apply pooling or down-sampling kernel.

00:01:11.785 --> 00:01:14.380
This is passed across the feature maps in

00:01:14.380 --> 00:01:16.850
the same way as a convolutional filter kernel.

00:01:16.850 --> 00:01:19.690
But this time we simply take the maximum value.

00:01:19.690 --> 00:01:21.040
The end result is

00:01:21.040 --> 00:01:22.840
a smaller feature map that tends

00:01:22.840 --> 00:01:25.640
to emphasize the activated pixels.

00:01:25.650 --> 00:01:28.870
So putting it all together,

00:01:28.870 --> 00:01:31.460
we start with an image,

00:01:31.460 --> 00:01:36.265
and then we use convolutional layers to apply filters.

00:01:36.265 --> 00:01:38.920
With pooling layers to down sample

00:01:38.920 --> 00:01:41.740
the feature maps generated by the filters.

00:01:41.740 --> 00:01:44.260
All of these layers form

00:01:44.260 --> 00:01:46.795
the feature extraction portion of our network.

00:01:46.795 --> 00:01:50.255
After which, we flattened the feature maps that we've extracted.

00:01:50.255 --> 00:01:52.430
Then we feed them into

00:01:52.430 --> 00:01:56.495
a fully connected layer to map them to class label probabilities.

00:01:56.495 --> 00:02:00.020
The whole thing is called a Convolutional Neural Network,

00:02:00.020 --> 00:02:01.310
and it's the basis for

00:02:01.310 --> 00:02:04.100
modern deep learning image classification solutions.

00:02:04.100 --> 00:02:07.010
We train it using the same train backpropagate

00:02:07.010 --> 00:02:08.120
and validate approach,

00:02:08.120 --> 00:02:10.310
we use for a fully connected neural network,

00:02:10.310 --> 00:02:12.170
adjusting the weights and biases in

00:02:12.170 --> 00:02:14.630
the fully connected neurons as well as

00:02:14.630 --> 00:02:18.090
the convolutional filter kernals in each epoch.
