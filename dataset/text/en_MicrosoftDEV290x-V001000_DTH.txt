>> Classification is a form of supervised machine learning, in which we train a model to determine the categorization or class of some item of interest. So does that actually mean? Well, it helps to think of machine learning models as mathematical functions. A function that operates on an input value, which we'll call x, and calculates an output value, which we'll call y. In machine learning terminology, x represents the features of the item that we're interested in. These are characteristics of the item usually numeric values. The y represents a label, the thing that we want to predict. In this case, that's the class of the object. Okay. Well, that all seems a bit abstract. So let's look at what's probably the quintessential example of classification, the Hello World of Machine Learning. In 1936, British statistician, Ronald Fisher, introduced a paper in which he described how to determine the species of iris flower based on the measurements of its sepals and petals. In this scenario, the features our x value, is a vector containing the height and width of the sepals and petals for the observed plants. Here's an example. The label, the y value we're trying to predict, is the species of iris of which there are three possible values; Setosa, Versicolor, and Virginica. We'll assign the values zero, one, and two to these classes. The y value generated by the function is a vector of probabilities, one for each of the possible classes. So in this example, the function predicts a zero percent probability of the first and third classes which are labeled zero and two and 100 percent probability for the second class, which we labeled one. So in this particular example, this flower is an example of a versicolor. So how did we define the function that calculates this probability vector? Well, we start with some historical observations of data where we already know the correct label values. In this case, iris measurements where we know the species. This dataset gives us some ground truth with which we can train a function. Now, we take some, but not all of our data and apply an algorithm such as logistic regression, which calculates coefficients that we can use to map the observation vectors into multidimensional space within which that are boundaries or thresholds that separate the different classes. Then we take the data that we held back and we use it to validate the model we've trained by applying the function to it. Ideally, it should assign each observation to the right class. We can then tabulate the results from our validation data into a structure called a confusion matrix which counts the predictions, intersecting the predicted classes with the actual known classes. In an ideal model, there should be a high number of cases where the predicted class matches the actual class, which shows up as a diagonal trend in the confusion matrix.